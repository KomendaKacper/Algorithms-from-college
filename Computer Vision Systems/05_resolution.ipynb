{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Rozdzielczość obrazu. Interpolacja.\n",
    "\n",
    "## Cel zajęć:\n",
    "\n",
    "* zapoznanie z pojęciem rozdzielczości przestrzennej (rozmiaru obrazu),\n",
    "* metody interpolacji najbliższego sąsiada oraz dwuliniowa,\n",
    "* zapoznanie z pojęciem rozdzielczości dpi (ang. dots per inch),\n",
    "* zapoznanie z pojęciem rozdzielczości  poziomów jasności (dla obrazów w skali szarości),\n",
    "* zadanie domowe: interpolacja dwusześcienna.\n",
    "\n",
    "## Rodzielczość przestrzenna\n",
    "\n",
    "Dyskretna reprezentacja obrazu to zwykle macierz dwu (N x M - obraz w skali szarości) lub trójwymiarowa (N x M x 3 - obraz kolorowy).\n",
    "Przez rozdzielczość przestrzenną rozumie się liczbę pikseli z których składa się obraz.\n",
    "Przykładowo rozdzielczość VGA to  640 x 480, Full HD to 1920 x 1080, a 4K to 3840 x 2160.\n",
    "Rozdzielczość obrazu można modyfikować (zwiększać/zmniejszać), co nazywa się skalowaniem obrazu.\n",
    "Warto wiedzieć, że zwiększenie rozdzielczości obrazu nie zwiększa ilości informacji, a jedynie liczbę pikseli (w sensie \"lepiej nie będzie\").\n",
    "Ponadto skalowanie zawsze wprowadza pewne zniekształcenia, nawet przy zmniejszaniu rozmiaru.\n",
    "\n",
    "W ramach niniejszego ćwiczenia zapoznamy się z metodami interpolacji, które są podstawą takich operacji jak: przybliżanie (zoom), zmiana rozdzielczości, rotacja obrazu, czy też korekcje geometryczne.\n",
    "Jako przykład posłuży nam zmiana rozdzielczości, czyli inaczej mówiąc przepróbkowanie obrazu.\n",
    "Dla przypomnienia - interpolacja to wykorzystanie znanych danych (wartości dla tzw. punktów węzłowych) do określania wartości w nieznanych lokalizacjach.\n",
    "\n",
    "Zacznijmy od prostego przykładu.\n",
    "Mamy obraz o rozdzielczości 500 x 500 pikseli, a chcemy go powiększyć do 750 x 750 pikseli -- tj. o~współczynnik 1,5.\n",
    "Wyobraźmy sobie zatem, że dysponujemy siatką 750 x 750 o takim samym \"rozmiarze\" pojedynczego piksela jak obraz oryginalny.\n",
    "Następnie siatkę tą ,,ścieśniamy'', tak aby miała rozmiar 500 x 500.\n",
    "W rezultacie otrzymana siatka będzie miała mniejszy rozmiar pojedynczego piksela niż obraz oryginalny.\n",
    "Schematycznie przedstawiono to na poniższym rysunku.\n",
    "\n",
    "![Ilustracja interpolacji](https://raw.githubusercontent.com/vision-agh/poc_sw/master/05_Resolution/img/interEx57.png)\n",
    "\n",
    "\n",
    "Pokazuje on przykład interpolacji: a) obraz 5x5, b) oraz 7x7, c) obraz 7x7 zmiejszony do 5x5.\n",
    "\n",
    "\n",
    "Chcemy teraz poszczególnym elementom nowej siatki przyporządkować piksele z obrazu wejściowego.\n",
    "Jedną z możliwości jest poszukanie \"najbliższego\" piksela w oryginalnym obrazie i wzięcie jego wartości.\n",
    "Przykład takiego postępowania zaprezentowano na  poniższym rysunku.\n",
    "\n",
    "![Ilustracja najbliższego sąsiada](https://raw.githubusercontent.com/vision-agh/poc_sw/master/05_Resolution/img/inteNNEx.png)\n",
    "\n",
    "Kilka słów wyjasnienia.\n",
    "Kolorem ciemnoszarym oznaczono siatkę 5x5, a czarnym 7x7 (już po przeskalowaniu).\n",
    "Nasze zadanie sprowadza się do znalezienia dla każdej kropki czarnej (umowny środek piksela), najbliżej leżącej kropki szarej - oznaczono to dla pierwszych trzech wierzszy obrazu liniami.\n",
    "\n",
    "Po zrealizowaniu powyższego kroku dla całego obrazu wykonujemy \"rozciągniecie\" do rozdzielczości 750 x 750.\n",
    "W ten sposób uzyskujemy finalny efekt zmiany rozdzielczości.\n",
    "\n",
    "## Interpolacja metodą najbliższego sąsiada\n",
    "\n",
    "Takie postępowanie określa się mianem **interpolacji metodą najbliższego sąsiada** (ang. *nearest neighbour interpolation*).\n",
    "W ramach pierwszego etapu ćwiczenia zaimplementujemy to podejście.\n",
    "\n",
    "1. Ładujemy potrzebne biblioteki, pobieramy obrazy z repozytorium, wczytujemy jeden z obrazów testowych (*parrot.bmp*) i wyświetlamy go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load required files\n",
    "if not os.path.exists(\"parrot.bmp\") :\n",
    "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/05_Resolution/parrot.bmp --no-check-certificate\n",
    "if not os.path.exists(\"clock.bmp\") :\n",
    "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/05_Resolution/clock.bmp --no-check-certificate\n",
    "if not os.path.exists(\"chessboard.bmp\") :\n",
    "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/05_Resolution/chessboard.bmp --no-check-certificate\n",
    "if not os.path.exists(\"lena.bmp\") :\n",
    "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/05_Resolution/lena.bmp --no-check-certificate\n",
    "if not os.path.exists(\"firetruck.jpg\") :\n",
    "    !wget https://raw.githubusercontent.com/vision-agh/poc_sw/master/05_Resolution/firetruck.jpg --no-check-certificate\n",
    "\n",
    "\n",
    "I = cv2.imread('parrot.bmp')           # Read image\n",
    "I = cv2.cvtColor(I, cv2.COLOR_BGR2GRAY) # Convert to RGB\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(I.shape[0]/100,I.shape[1]/100), dpi=200)\n",
    "plt.imshow(I, cmap =\"gray\")\n",
    "plt.xticks([]), plt.yticks([])  # Hides the graph ticks and x / y axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. Definiujemy funkcję do interpolacji metodą najbliższego sąsiada.\n",
    "\n",
    "Jako argumenty wejściowe powinna ona przyjąć obraz oraz współczynniki skalowania w pionie i poziomie.\n",
    "Wyjściem powinien być natomiast obraz w nowej rozdzielczości.\n",
    "Wewnątrz należy:\n",
    "\n",
    "* odczytać wymiary obrazka wejściowego,\n",
    "* wyliczyć wymiary obrazka wyjściowego (tj. wymnożyć wymiary wejściowe przez skalę i zaokrąglić do liczb całkowitych),\n",
    "* utworzyć nowy obraz o ww. rozmiarze,\n",
    "* w pętli po nowym obrazie, dla każdego piksela, wykorzystując współczynniki skalowania, odnaleźć najbliższego sąsiada.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def nearest_neighbor(image, scale_x, scale_y):\n",
    "    height, width = image.shape\n",
    "    new_width = int(width * scale_x)\n",
    "    new_height = int(height * scale_y)\n",
    "    new_image = np.zeros((new_height, new_width), dtype=np.uint8)\n",
    "    scalex = 1.0 / scale_x\n",
    "    scaley = 1.0 / scale_y\n",
    "    for y in range(new_height):\n",
    "        for x in range(new_width):\n",
    "            origx = int(x * scalex)\n",
    "            origy = int(y * scaley)\n",
    "            new_image[y, x] = image[origy, origx]\n",
    "    return new_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Testujemy stworzoną funkcję:\n",
    "    * dla skali 1.5, 1.5 i obrazka *parrot*,\n",
    "    * dla 2.5, 2.5 - tu okaże się, że do kodu trzeba dopisać zabezpieczenie przed wyjściem poza zakres,\n",
    "    * dla niejednakowych skal np. 1.5 i 2.5,\n",
    "    * dla skal mniejszych od 1,\n",
    "    * dla niesymetrycznego obrazka *clock*,\n",
    "    * dla obrazka z szachownicą *chessboard*.\n",
    "\n",
    "Uwaga: proszę dla powyższych przypadków przygotować osobne sekcje kodu - tak, aby wyświetlały się wszystkie rozważane przypadki.\n",
    "\n",
    "Wykonana metoda jest bardzo prosta i szybka, ale wprowadza pewne niepożądane artefakty, w szczególnie źle odwzorowane są linie proste.\n",
    "Z drugiej strony sprawdza się w pewnych nietypowych przypadkach.\n",
    "Zostanie to zademonstrowane w dalszej części ćwiczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(I.shape[0]/100, I.shape[1]/100), dpi=200)\n",
    "plt.imshow(I, cmap='gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "scaled_image = nearest_neighbor(I, 1.5, 1.5)\n",
    "\n",
    "plt.figure(figsize=(scaled_image.shape[0]/100, scaled_image.shape[1]/100), dpi=200)\n",
    "plt.imshow(scaled_image, cmap='gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_image = nearest_neighbor(I, 2.5, 2.5)\n",
    "\n",
    "plt.figure(figsize=(scaled_image.shape[0]/100, scaled_image.shape[1]/100), dpi=200)\n",
    "plt.imshow(scaled_image, cmap='gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_image = nearest_neighbor(I, 1.5, 2.5)\n",
    "\n",
    "plt.figure(figsize=(scaled_image.shape[0]/100, scaled_image.shape[1]/100), dpi=200)\n",
    "plt.imshow(scaled_image, cmap='gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_image = nearest_neighbor(I, 0.5, 0.5)\n",
    "\n",
    "plt.figure(figsize=(scaled_image.shape[0]/100, scaled_image.shape[1]/100), dpi=200)\n",
    "plt.imshow(scaled_image, cmap='gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = cv2.imread('clock.bmp')\n",
    "I = cv2.cvtColor(I, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "scaled_image = nearest_neighbor(I, 0.7, 0.7)\n",
    "\n",
    "plt.figure(figsize=(scaled_image.shape[0]/100, scaled_image.shape[1]/100), dpi=200)\n",
    "plt.imshow(scaled_image, cmap='gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = cv2.imread('chessboard.bmp')\n",
    "I = cv2.cvtColor(I, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "scaled_image = nearest_neighbor(I, 15, 15)\n",
    "\n",
    "plt.figure(figsize=(scaled_image.shape[0]/100, scaled_image.shape[1]/100), dpi=200)\n",
    "plt.imshow(scaled_image, cmap='gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Interpolacja dwuliniowa\n",
    "\n",
    "W praktyce, lepszym rozwiązaniem zwykle okazuje tzw. **interpolacja dwuliniowa** (ang. *bilinear interpolation*).\n",
    "Wykorzystuje ona informację o czterech najbliższych sąsiadach do określenia nowej wartości piksela.\n",
    "\n",
    "Jeśli przez $(i,j)$ oznaczymy współrzędne poszukiwanego piksela, a przez $I(i,j)$ jego jasność (składową w~odcieniach szarości) to jego wartość można obliczyć wykorzystując równanie:\n",
    "\\begin{equation}\n",
    "I(i,j) = a \\cdot i + b \\cdot j+ c \\cdot i \\cdot j + d\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "gdzie: współczynniki $a,b,c,d$ można wyliczyć na podstawie czterech najbliższych sąsiadów.\n",
    "\n",
    "![Ilustracja dwuliniowej](https://raw.githubusercontent.com/vision-agh/poc_sw/master/05_Resolution/img/interABCD.png)\n",
    "\n",
    "Prześledźmy to na przykładzie z powyższego rysunku.\n",
    "Niech współrzędne poszczególnych punktów to $A = (j_1,i_1)$, $B = (j_1,i_2)$, $C= (j_2,i_2)$ oraz $D = (j_2,i_1)$.\n",
    "W pierwszej kolejności dokonujemy interpolacji wartości w punktach $AB$ i $CD$ -- czyli poziomo.\n",
    "Wychodząc od równania prostej otrzymujemy:\n",
    "\n",
    "\\begin{equation}\n",
    "f(AB) \\approx \\frac{i_2 - i}{i_2-i_1}f(A) + \\frac{i - i_1}{i_2-i_1}f(B)\n",
    "\\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "f(CD) \\approx \\frac{i_2 - i}{i_2-i_1}f(D) + \\frac{i - i_1}{i_2-i_1}f(C)\n",
    "\\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "Następnie wykonujemy analogiczną interpolację w pionie:\n",
    "\\begin{equation}\n",
    "f(ABCD) \\approx \\frac{j_2 - j}{j_2-j_1}f(AB) + \\frac{j - j_1}{j_2-j_1}f(CD)\n",
    "\\tag{4}\n",
    "\\end{equation}\n",
    "\n",
    "Łącząc powyższe równania otrzymujemy:\n",
    "\\begin{equation}\n",
    "f(ABCD) \\approx \\frac{1}{(i_2 - i_1)(j_2-j_1)} ( f(A)(i_2-i)(j_2 - y) + f(B)(i-i_1)(j_2 - j) \\\\ + f(C)(i-i_1)(j-j_1) + f(D)(i_2-i)(j-j_1))\n",
    "\\tag{5}\n",
    "\\end{equation}\n",
    "gdzie zapis $f(X)$ oznacza wartość piksela w punkcie $X$.\n",
    "\n",
    "Rozważania można uprościć przyjmując, że narożniki rozpatrywanego kwadratu mają następujące współrzędne: $A = (0,0)$, $B = (0,1)$, $C= (1,1)$ oraz $D = (1,0)$.\n",
    "Wtedy powyższe równanie można zapisać:\n",
    "\\begin{equation}\n",
    "f(ABCD) \\approx f(A)(1-i)(1-j) + f(B)i(1-j) + f(C)ij + f(D)(1-i)j\n",
    "\\tag{6}\n",
    "\\end{equation}\n",
    "\n",
    "lub macierzowo:\n",
    "\\begin{equation}\n",
    "f(ABCD) \\approx \\begin{bmatrix}1 - i & i \\end{bmatrix} \\begin{bmatrix} f(A) & f(D) \\\\\\\\ f(B) & f(C)  \\end{bmatrix}   \\begin{bmatrix} 1-j \\\\\\\\ j  \\end{bmatrix}\n",
    "\\tag{7}\n",
    "\\end{equation}\n",
    "\n",
    "Uwaga.\n",
    "Nieco wbrew nazwie interpolacja dwuliniowa nie jest operacją liniową.\n",
    "W złożeniu dwóch operacji liniowych pojawia się człon $xy$.\n",
    "\n",
    "Warto dodać, że kolejny ``poziom wtajemniczenia'' to **interpolacja dwusześcienna** (ang. *bicubic interpolation*).\n",
    "Dana jest ona wzorem:\n",
    "\\begin{equation}\n",
    "I(i,j) = \\sum_{i=0}^{3} \\sum_{j=0}^{3} a_{ij} x^i y^j\n",
    "\\tag{8}\n",
    "\\end{equation}\n",
    "Jej implementacja stanowi zadanie domowe do bieżącego ćwiczenia.\n",
    "\n",
    "Trzy powyżej przedstawione metody bynajmniej nie wyczerpują tematu.\n",
    "Wystarczy choćby otworzyć stronę [wiki o skalowaniu](https://en.wikipedia.org/wiki/Image_scaling), by zobaczyć, że metod jest dużo więcej.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Wykorzystując powyższe równania zaimplementuj interpolację dwuliniową:\n",
    "* dobrym punktem wyjścia będzie stworzona funkcja do interpolacji metodą najbliższego sąsiada,\n",
    "* początek powinien być identyczny,\n",
    "* różnice rozpoczynają się w momencie obliczenia współrzędnych nowego piksela,\n",
    "* jeśli chcemy zastosować opisane powyżej wzory (w wariancie uproszczonym), to musimy wyliczyć współrzędne punktów $A,B,C,D$,\n",
    "* w pierwszym kroku obliczamy współrzędne $A$ tj. $(0,0)$ - należy do tego wykorzystać funkcję *floor* (np. $i_1 = floor(i / h_{scale})$).\n",
    "  Proszę ten krok odnieść do przedstawionego rysunku poglądowego,\n",
    "* obliczenie współrzędnych $B,C,D$ jest już proste i sprowadza się do operacji `+1`,\n",
    "* potrzebujemy jeszcze część ułamkową współrzędnych punktu $ABCD$ tj. $(i,j)$ - od ilorazu $i/h_{scale}$ należy odjąć wartość $i_1$\n",
    "* wykorzystując wyznaczone współrzędne, należy pobrać wartości jasności w punktach $A,B,C,D$, tj. $f(A),f(B),f(C),f(D)$, podstawić do odpowiedniego równania i wykonać interpolację.\n",
    "\n",
    "  Uwagi:\n",
    "* Tworzenie macierzy *np.array*, mnożenie macierzy *np.dot*. Przy tworzeniu macierzy proszę zwrócić uwagę na niezbędne nawiasy kwadratowe.\n",
    "* Przy próbie uruchomienia kodu pewnie okaże się, że wystąpi przekroczenie zakresu - należy dodać stosowne zabezpieczenie.\n",
    "\n",
    "Proszę dla interpolacji dwuliniowej wykonać takie same eksperymenty, jak dla  najbliższego sąsiada.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolacja_dwuliniowa(image, scale_x, scale_y):\n",
    "    (rows, cols) = image.shape\n",
    "    new_rows = int(np.round(scale_x * rows))\n",
    "    new_cols = int(np.round(scale_y * cols))\n",
    "    \n",
    "    new_image = np.zeros((new_rows, new_cols), dtype=np.float64)\n",
    "\n",
    "    \n",
    "    for i in range(new_rows):\n",
    "        for j in range(new_cols):\n",
    "            old_i = i / scale_x\n",
    "            old_j = j / scale_y\n",
    "            \n",
    "            i1 = int(np.floor(old_i))\n",
    "            i2 = int(np.floor(old_i + 1))\n",
    "            j1 = int(np.floor(old_j))\n",
    "            j2 = int(np.floor(old_j + 1))\n",
    "            \n",
    "            if i2 >= rows:\n",
    "                i2 = rows - 1\n",
    "            if j2 >= cols:\n",
    "                j2 = cols - 1\n",
    "                \n",
    "            if i1 == i2:\n",
    "                i1 -= 1\n",
    "            if j1 == j2:\n",
    "                j1 -= 1\n",
    "\n",
    "            A = image[i1, j1]\n",
    "            B = image[i1, j2]\n",
    "            C = image[i2, j2]\n",
    "            D = image[i2, j1]\n",
    "            \n",
    "            fAB = ((j2 - old_j) / (j2 - j1)) * A + ((old_j - j1) / (j2 - j1)) * B\n",
    "            fCD = ((j2 - old_j) / (j2 - j1)) * C + ((old_j - j1) / (j2 - j1)) * D\n",
    "            fABCD = ((i2 - old_i) / (i2 - i1)) * fAB + ((old_i - i1) / (i2 - i1)) * fCD\n",
    "            \n",
    "            new_image[i, j] = int(np.round(fABCD))\n",
    "    return new_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = cv2.imread('parrot.bmp')           \n",
    "I = cv2.cvtColor(I, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure(figsize=(I.shape[0]/100, I.shape[1]/100), dpi=200)\n",
    "plt.imshow(I, cmap='gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "scaled_image = interpolacja_dwuliniowa(I, 1.5, 1.5)\n",
    "\n",
    "plt.figure(figsize=(scaled_image.shape[0]/100, scaled_image.shape[1]/100), dpi=200)\n",
    "plt.imshow(scaled_image, cmap='gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_image = interpolacja_dwuliniowa(I, 2.5, 2.5)\n",
    "\n",
    "plt.figure(figsize=(scaled_image.shape[0]/100, scaled_image.shape[1]/100), dpi=200)\n",
    "plt.imshow(scaled_image, cmap='gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_image = interpolacja_dwuliniowa(I, 1.5, 2.5)\n",
    "\n",
    "plt.figure(figsize=(scaled_image.shape[0]/100, scaled_image.shape[1]/100), dpi=200)\n",
    "plt.imshow(scaled_image, cmap='gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_image = interpolacja_dwuliniowa(I, 0.5, 0.5)\n",
    "\n",
    "plt.figure(figsize=(scaled_image.shape[0]/100, scaled_image.shape[1]/100), dpi=200)\n",
    "plt.imshow(scaled_image, cmap='gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = cv2.imread('clock.bmp')\n",
    "I = cv2.cvtColor(I, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "scaled_image = interpolacja_dwuliniowa(I, 0.7, 0.7)\n",
    "\n",
    "plt.figure(figsize=(scaled_image.shape[0]/100, scaled_image.shape[1]/100), dpi=200)\n",
    "plt.imshow(scaled_image, cmap='gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = cv2.imread('chessboard.bmp')\n",
    "I = cv2.cvtColor(I, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "scaled_image = interpolacja_dwuliniowa(I, 15, 15)\n",
    "\n",
    "plt.figure(figsize=(scaled_image.shape[0]/100, scaled_image.shape[1]/100), dpi=200)\n",
    "plt.imshow(scaled_image, cmap='gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Interpolacja w OpenCV\n",
    "\n",
    "W OpenCV dostępna jest funkcja `resize`, która służy do zmiany rozmiaru obrazka.\n",
    "Składnia jest następująca `dst = cv2.resize(\tsrc, dsize[, dst[, fx[, fy[, interpolation]]]] )`, gdzie `det` to obraz wynikowy, `src` obraz źródłowy, `dsize` rozmiar docelowy (ew. można podać współczynniki skalowania dla poszczególnych osi: `fx,fy`), `interpolation` metoda interpolacji.\n",
    "Metod podstawowych dostępnych jest 5:\n",
    "- najbliższego sąsiada - ` cv2.INTER_NEAREST`,\n",
    "- dwuliniowa - ` cv2.INTER_LINEAR`,\n",
    "- dwukubiczna - ` cv2.INTER_CUBIC`,\n",
    "- *area* - ` cv2.INTER_AREA`,\n",
    "- *lanczos4* - ` cv2.INTER_LANCZOS4`.\n",
    "\n",
    "Przeprowadzimy następujący eksperyment: obraz (o większej niż dotąd rozdzielczości) przeskalujemy każdą z metod -- zwiększymy i zmniejszymy jego rozdzielczość. Dodamy też pomiar czasu realizacji obliczeń.\n",
    "\n",
    "Obraz: TODO\n",
    "\n",
    "\n",
    "Proszę stworzyć funkcję, która jako argumenty przyjmuje obraz oraz dwa współczynniki skalujące, a wewnątrz przeprowadzone zostaną interpolacje, pomiar czasu oraz wizualizacja (można wypisać czas w tytule rysunku).\n",
    "\n",
    "Pomiar czasu:\n",
    "```{python}\n",
    "from timeit import default_timer as timer\n",
    "start = timer()\n",
    "# ...\n",
    "end = timer()\n",
    "print(end - start)\n",
    "```\n",
    "\n",
    "Wykonaj eksperyment dla kilku różnych skal, przeanalizuj czasy obliczeń."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def resize_and_visualize(image, scale_x, scale_y, interpolation):\n",
    "    start = timer()\n",
    "    scaled_image = cv2.resize(image, None, fx=scale_x, fy=scale_y, interpolation=interpolation)\n",
    "    end = timer()\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(scaled_image, cmap='gray')\n",
    "    plt.title(\"Interpolacja: {}, {:.5f} sekund\".format(interpolation, end - start))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "I = cv2.imread('parrot.bmp')\n",
    "I = cv2.cvtColor(I, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_x, scale_y = 2, 2\n",
    "resize_and_visualize(I, scale_x, scale_y, cv2.INTER_NEAREST)\n",
    "resize_and_visualize(I, scale_x, scale_y, cv2.INTER_LINEAR)\n",
    "resize_and_visualize(I, scale_x, scale_y, cv2.INTER_CUBIC)\n",
    "resize_and_visualize(I, scale_x, scale_y, cv2.INTER_AREA)\n",
    "resize_and_visualize(I, scale_x, scale_y, cv2.INTER_LANCZOS4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najwolniejszy jest sposób interpolacji Lanczos4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Rozdzielczość (dpi)\n",
    "\n",
    "Omówioną wcześniej rozdzielczość przestrzenną (rozmiar) należy utożsamiać z rozmiarem macierzy w której zapisany jest obraz.\n",
    "W tym ujęciu rozmiar pojedynczego piksela nie ma specjalnego znaczenia.\n",
    "Problem pojawia się, kiedy obraz trzeba wyświetlić lub wydrukować.\n",
    "Wtedy pojedynczy piksel staje się ,,obiektem fizycznym'' i musi mieć swój rozmiar (wysokość/szerokość/powierzchnię).\n",
    "\n",
    "Parametr dpi (ang. *dots per inch*) określa liczbę kropek (pikseli), która mieści się na jednym calu (25,4 mm) długości/szerokości.\n",
    "Dopiero kombinacja rozmiaru i rozdzielczości określa nam rzeczywisty rozmiar obrazu jaki uzyskamy na wydruku.\n",
    "\n",
    "Dpi staje się istotne w przypadku drukowania, gdyż wyświetlanie na monitorze odbywa się zazwyczaj 1 piksel obrazka = 1 piksel na monitorze (w przypadku maksymalnej rozdzielczości wspieranej przez monitor), ew. następuje automatyczne skalowanie.\n",
    "\n",
    "Wpływ rozdzielczości można zademonstrować w następujący sposób:\n",
    "- wczytaj obraz *lena.bmp*.  Ma on rozmiar $512 \\times 512$.\n",
    "- wykorzystując funkcję `imresize` stwórz obrazy o rozmiarach $256 \\times 256$, $128 \\times 128$, $64 \\times 64$ - metoda interpolacji jest w tym wypadku mniej istotna.\n",
    "- wyświetl obrazy wymuszając zachowanie na ekranie wejściowej rozdzielczości $512 \\times 512$. W przypadku biblioteki *matplotlib* ta funkcjonalność jest domyślna.\n",
    "\n",
    "Proszę zaobserwować co dzieję się z obrazkiem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lena = cv2.imread('lena.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "lena_256 = cv2.resize(lena, (256, 256))\n",
    "lena_128 = cv2.resize(lena, (128, 128))\n",
    "lena_64 = cv2.resize(lena, (64, 64))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(131), plt.imshow(lena_256, cmap='gray'), plt.title('256x256')\n",
    "plt.subplot(132), plt.imshow(lena_128, cmap='gray'), plt.title('128x128')\n",
    "plt.subplot(133), plt.imshow(lena_64, cmap='gray'), plt.title('64x64')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z moich wyników wynika, że rozdzielczość obrazu znacząco wpływa na jego ostrość. Wraz z jej spadkiem, maleje ostrość obrazu, piksele są coraz bardziej widoczne gołym okiem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Liczba poziomów jasności\n",
    "\n",
    "Dla obrazów w skali szarości pojedynczy piksel zwykle zapisuje się na 8 bitach, co daje 256 rozróżnialnych poziomów szarości.\n",
    "Dla większości zastosowań wartość ta jest wystarczająca (choć są kamery o wyjścu 12 lub 16 bitów).\n",
    "Jednak oko ludzkie nie potrafi rozróżnić wszystkich 256 poziomów jasności (jest za mało czułe).\n",
    "Zazwyczaj człowiek rozróżnia 20-30 poziomów szarości (to ile i jakie dokładnie rozróżnia, zależy od konkretnego oświetlenia sceny i cech osobniczych).\n",
    "\n",
    "W poniższych krokach zademonstrujemy omówione zjawisko:\n",
    "- wczytaj (użyj) obrazu _lena_,\n",
    "- wykorzystując znaną funkcję `normalize` zmień liczbę poziomów szarości z 0-255 na:\n",
    "    * 0-31\n",
    "    * 0-15\n",
    "    * 0-7\n",
    "    * 0-3\n",
    "    * 0-1 (binaryzacja)\n",
    "- rezultaty wyświetl na wspólnym rysunku.\n",
    "\n",
    "Podpowiedzi:\n",
    "- trzeba przygotować tablice na obrazki np, `I_31 = np.zeros(I.shape,'uint8')`,\n",
    "- prawidłowe użycie funkcji normalize `cv2.normalize(I,I_31,0,31,cv2.NORM_MINMAX)`,\n",
    "- przykładowe wyświetlanie `axsHist[0,1].imshow(I, 'gray', vmin=0, vmax=31)`.\n",
    "\n",
    "Czy rezultaty eksperymentu pasują do teorii o rozpoznawaniu przez człowieka ograniczonego zakresu poziomów jasności?\n",
    "Wizualne porównanie których obrazów o tym świadczy ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lena_original = cv2.imread('lena.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "lena = cv2.imread('lena.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "lena_31 = np.zeros(lena.shape, dtype='uint8')\n",
    "lena_15 = np.zeros(lena.shape, dtype='uint8')\n",
    "lena_7 = np.zeros(lena.shape, dtype='uint8')\n",
    "lena_3 = np.zeros(lena.shape, dtype='uint8')\n",
    "lena_1 = np.zeros(lena.shape, dtype='uint8')\n",
    "\n",
    "cv2.normalize(lena, lena_31, 0, 31, cv2.NORM_MINMAX)\n",
    "cv2.normalize(lena, lena_15, 0, 15, cv2.NORM_MINMAX)\n",
    "cv2.normalize(lena, lena_7, 0, 7, cv2.NORM_MINMAX)\n",
    "cv2.normalize(lena, lena_3, 0, 3, cv2.NORM_MINMAX)\n",
    "_, lena_1 = cv2.threshold(lena, 127, 1, cv2.THRESH_BINARY)\n",
    "\n",
    "fig, axs = plt.subplots(1, 6, figsize=(20, 5))\n",
    "\n",
    "axs[0].imshow(lena_original, cmap='gray')\n",
    "axs[0].set_title('Oryginalny')\n",
    "\n",
    "axs[1].imshow(lena_31, cmap='gray', vmin=0, vmax=31)\n",
    "axs[1].set_title('poziomy 0-31')\n",
    "\n",
    "axs[2].imshow(lena_15, cmap='gray', vmin=0, vmax=15)\n",
    "axs[2].set_title('poziomy 0-15')\n",
    "\n",
    "axs[3].imshow(lena_7, cmap='gray', vmin=0, vmax=7)\n",
    "axs[3].set_title('poziomy 0-7')\n",
    "\n",
    "axs[4].imshow(lena_3, cmap='gray', vmin=0, vmax=3)\n",
    "axs[4].set_title('poziomy 0-3')\n",
    "\n",
    "axs[5].imshow(lena_1, cmap='gray', vmin=0, vmax=1)\n",
    "axs[5].set_title('binarnie (0-1)')\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obrazy na poziomach 0-31 oraz 0-15 są niemalże nierozróżnialne. Można zatem stwierdzić, że wyniki eksperymentu po części pasują do teorii rozpoznawania przez człowieka ograniczonego zakresu poziomów jasności."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
